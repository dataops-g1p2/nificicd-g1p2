name: Provision Infrastructure

on:
  workflow_dispatch:
    inputs:
      environments:
        description: 'Environment(s) to provision (comma-separated: development,staging,production)'
        required: true
        type: string
        default: 'development'
      force_recreate:
        description: 'Force recreate if infrastructure exists?'
        required: false
        type: boolean
        default: false
      wait_time:
        description: 'Wait time between environments (seconds)'
        required: false
        type: number
        default: 60
      terraform_destroy_on_failure:
        description: 'Auto-cleanup infrastructure if provisioning fails?'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  actions: read

jobs:
  determine-environments:
    name: Determine Target Environments
    runs-on: ubuntu-22.04
    outputs:
      environments: ${{ steps.set_envs.outputs.environments }}
      environment_list: ${{ steps.set_envs.outputs.environment_list }}
    steps:
      - name: Parse and Validate Environments
        id: set_envs
        run: |
          INPUT="${{ github.event.inputs.environments }}"
          INPUT=$(echo "$INPUT" | tr -d ' ' | tr '[:upper:]' '[:lower:]')
          IFS=',' read -ra ENV_ARRAY <<< "$INPUT"
          
          VALID_ENVS=()
          INVALID_ENVS=()
          
          for env in "${ENV_ARRAY[@]}"; do
            case "$env" in
              development|staging|production)
                [[ ! " ${VALID_ENVS[@]} " =~ " ${env} " ]] && VALID_ENVS+=("$env")
                ;;
              *)
                INVALID_ENVS+=("$env")
                ;;
            esac
          done
          
          [ ${#INVALID_ENVS[@]} -gt 0 ] && echo "Invalid: ${INVALID_ENVS[*]}" && exit 1
          [ ${#VALID_ENVS[@]} -eq 0 ] && echo "No valid environments" && exit 1
          
          JSON_ARRAY=$(printf '%s\n' "${VALID_ENVS[@]}" | jq -R . | jq -s .)
          ENV_LIST=$(IFS=','; echo "${VALID_ENVS[*]}")
          
          echo "environments=$JSON_ARRAY" >> $GITHUB_OUTPUT
          echo "environment_list=$ENV_LIST" >> $GITHUB_OUTPUT
          echo "Validated environments: ${VALID_ENVS[*]}"

  check-and-destroy:
    name: Check/Destroy ${{ matrix.environment }}
    needs: determine-environments
    runs-on: ubuntu-22.04
    strategy:
      matrix:
        environment: ${{ fromJson(needs.determine-environments.outputs.environments) }}
      fail-fast: false
    environment: ${{ matrix.environment }}
    steps:
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: |
            {
              "clientId": "${{ secrets.ARM_CLIENT_ID }}",
              "clientSecret": "${{ secrets.ARM_CLIENT_SECRET }}",
              "subscriptionId": "${{ secrets.ARM_SUBSCRIPTION_ID }}",
              "tenantId": "${{ secrets.ARM_TENANT_ID }}"
            }
            
      - name: Check and Optionally Destroy Infrastructure
        run: |
          ENV="${{ matrix.environment }}"
          RG_SUFFIX="${ENV/development/dev}"
          RG="rg-nificicd-g1p2-$RG_SUFFIX"
          VM_NAME="vm-nifi-$ENV"
          
          echo "Checking $ENV infrastructure..."
          
          if az group exists --name $RG | grep -q "true" && az vm show --resource-group $RG --name $VM_NAME &>/dev/null; then
            VM_IP=$(az vm show -d --resource-group $RG --name $VM_NAME --query publicIps -o tsv)
            echo "Infrastructure exists - VM IP: $VM_IP"
            
            if [ "${{ github.event.inputs.force_recreate }}" = "true" ]; then
              echo "FORCE RECREATE - Deleting resource group: $RG"
              az group delete --name $RG --yes --no-wait
              
              echo "Waiting for deletion..."
              for i in {1..30}; do
                if ! az group exists --name $RG | grep -q "true"; then
                  echo "Resource group deleted"
                  exit 0
                fi
                echo "  Waiting... ($i/30)"
                sleep 10
              done
              
              if az group exists --name $RG | grep -q "true"; then
                echo "ERROR: Deletion timed out - check Azure Portal"
                exit 1
              fi
            fi
          else
            echo "No existing infrastructure"
          fi
          
  setup-secrets:
    name: Setup Secrets - ${{ matrix.environment }}
    needs: [determine-environments, check-and-destroy]
    if: always() && needs.determine-environments.result == 'success'
    runs-on: ubuntu-22.04
    strategy:
      matrix:
        environment: ${{ fromJson(needs.determine-environments.outputs.environments) }}
      fail-fast: false
    environment: ${{ matrix.environment }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      
      - name: Check and Generate SSH Keys
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          ENV="${{ matrix.environment }}"
          
          # Check if valid SSH keys exist
          if [ -n "${{ secrets.SSH_PUBLIC_KEY }}" ] && [ -n "${{ secrets.SSH_PRIVATE_KEY }}" ]; then
            KEY=$(echo "${{ secrets.SSH_PUBLIC_KEY }}" | xargs)
            if [[ "$KEY" =~ ^(ssh-rsa|ssh-ed25519|ecdsa-sha2-nistp256)[[:space:]] ]]; then
              echo "SSH keys already configured"
              exit 0
            fi
          fi
          
          echo "Generating SSH key pair for $ENV..."
          
          if [ -z "$GH_TOKEN" ] || ! gh auth status &>/dev/null; then
            cat <<ERROR
          
          ERROR: GH_TOKEN not found or invalid
          
          Please add GH_TOKEN to repository secrets:
            1. Settings → Secrets and variables → Actions
            2. Create: GH_TOKEN
            3. Generate at: https://github.com/settings/tokens
            4. Required scopes: repo, workflow
          
          ERROR
            exit 1
          fi
          
          mkdir -p ~/.ssh && chmod 700 ~/.ssh
          ssh-keygen -t rsa -b 4096 -f ~/.ssh/nifi_key_${ENV} -N "" -C "nifi-${ENV}"
          
          cat ~/.ssh/nifi_key_${ENV}.pub | gh secret set SSH_PUBLIC_KEY --env $ENV
          cat ~/.ssh/nifi_key_${ENV} | gh secret set SSH_PRIVATE_KEY --env $ENV
          
          echo "SSH keys configured"

      - name: Setup Environment Secrets
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          ENV="${{ matrix.environment }}"
          
          # Helper function
          set_secret() { echo "$2" | gh secret set "$1" --env $ENV 2>/dev/null; }
          
          # VM Configuration
          set_secret "VM_USERNAME" "azureuser"
          set_secret "VM_SSH_PORT" "22"
          set_secret "NIFI_USERNAME" "admin"
          
          # Generate passwords if missing
          [ -z "${{ secrets.NIFI_PASSWORD }}" ] && set_secret "NIFI_PASSWORD" "$(openssl rand -hex 16)"
          [ -z "${{ secrets.NIFI_SENSITIVE_PROPS_KEY }}" ] && set_secret "NIFI_SENSITIVE_PROPS_KEY" "$(openssl rand -hex 12)"
          
          # Ports
          set_secret "NIFI_HTTPS_PORT" "8443"
          set_secret "NIFI_REGISTRY_PORT" "18080"
          
          echo "Secrets configured for $ENV"

  provision-and-configure:
    name: Provision ${{ matrix.environment }}
    needs: [determine-environments, setup-secrets]
    if: always() && needs.setup-secrets.result == 'success'
    runs-on: ubuntu-22.04
    strategy:
      matrix:
        environment: ${{ fromJson(needs.determine-environments.outputs.environments) }}
      max-parallel: 1
      fail-fast: false
    environment: ${{ matrix.environment }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: |
            {
              "clientId": "${{ secrets.ARM_CLIENT_ID }}",
              "clientSecret": "${{ secrets.ARM_CLIENT_SECRET }}",
              "subscriptionId": "${{ secrets.ARM_SUBSCRIPTION_ID }}",
              "tenantId": "${{ secrets.ARM_TENANT_ID }}"
            }

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~> 1.5"
          terraform_wrapper: false
          
      - name: Provision VM with Terraform
        working-directory: ./azure-vm-terraform
        env:
          ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
          TF_VAR_environment: ${{ matrix.environment }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_azure_subscription_id: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        run: |
          terraform init -input=false
          terraform validate
          terraform plan -var-file="${{ matrix.environment }}.tfvars" -out=tfplan -input=false
          terraform apply -auto-approve tfplan
        
      - name: Get VM IP and Wait for Readiness
        id: vm_ready
        working-directory: ./azure-vm-terraform
        env:
          ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
        run: |
          VM_IP=$(terraform output -raw vm_public_ip)
          echo "::add-mask::$VM_IP"
          echo "ip=$VM_IP" >> $GITHUB_OUTPUT
          echo "VM IP obtained"
          
          ENV="${{ matrix.environment }}"
          RG_SUFFIX="${ENV/development/dev}"
          RG="rg-nificicd-g1p2-$RG_SUFFIX"
          VM_NAME="vm-nifi-$ENV"
          
          # Wait for VM to be fully running
          echo "Waiting for VM to be fully running..."
          for i in {1..60}; do
            STATUS=$(az vm get-instance-view --resource-group $RG --name $VM_NAME \
              --query "instanceView.statuses[?code=='PowerState/running'].code" -o tsv 2>/dev/null)
            
            if [ "$STATUS" == "PowerState/running" ]; then
              echo "VM is running"
              sleep 20
              break
            fi
            
            echo "Attempt $i/60 - waiting..."
            sleep 5
          done
          
          [ "$STATUS" != "PowerState/running" ] && echo "ERROR: VM did not reach running state" && exit 1

      - name: Update Secrets with VM Details
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          VM_IP="${{ steps.vm_ready.outputs.ip }}"
          ENV="${{ matrix.environment }}"
          
          echo "$VM_IP" | gh secret set VM_PUBLIC_IP --env "$ENV"
          echo "$VM_IP:8443" | gh secret set NIFI_WEB_PROXY_HOST --env "$ENV"
          echo "https://$VM_IP:8443" | gh secret set NIFI_URL --env "$ENV"
          echo "http://$VM_IP:18080" | gh secret set REGISTRY_URL --env "$ENV"
          
          echo "Secrets updated"

      - name: Setup SSH and Install Ansible
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/nifi_key
          chmod 600 ~/.ssh/nifi_key
          sudo apt-get update && sudo apt-get install -y ansible

      - name: Wait for SSH
        run: |
          VM_IP="${{ steps.vm_ready.outputs.ip }}"
          echo "Waiting for SSH..."
          
          for i in {1..30}; do
            if ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=5 \
                   -i ~/.ssh/nifi_key ${{ secrets.VM_USERNAME }}@$VM_IP "echo SSH Ready" 2>/dev/null; then
              echo "SSH ready"
              exit 0
            fi
            echo "Attempt $i/30..."
            sleep 10
          done
          
          echo "ERROR: SSH timeout"
          exit 1

      - name: Configure VM with Ansible
        env:
          GITHUB_PAT: ${{ secrets.GH_TOKEN }}
          NIFI_ENVIRONMENT: ${{ matrix.environment }}
        run: |
          cat > inventory.ini <<EOF
          [${{ matrix.environment }}]
          ${{ steps.vm_ready.outputs.ip }} ansible_user=${{ secrets.VM_USERNAME }} ansible_ssh_private_key_file=~/.ssh/nifi_key ansible_ssh_common_args='-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
          EOF
          
          ansible-playbook -i inventory.ini ansible/configure-vm.yml \
            -e "nifi_environment=${NIFI_ENVIRONMENT}" \
            -e "github_repo=${{ github.repository }}" \
            -e "github_pat=${GITHUB_PAT}" -v

      - name: Update and Validate Configuration
        run: |
          VM_IP="${{ steps.vm_ready.outputs.ip }}"
          VM_USER="${{ secrets.VM_USERNAME }}"
          ENV="${{ matrix.environment }}"
          
          # Update environment file
          echo "Updating .env.$ENV..."
          ssh -i ~/.ssh/nifi_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            $VM_USER@$VM_IP "cat > ~/nificicd-g1p2/.env.$ENV <<'EOF'
          # Docker Compose Environment File for $ENV
          # Generated: $(date -u +%Y-%m-%d\ %H:%M:%S\ UTC)
          
          NIFI_USERNAME=${{ secrets.NIFI_USERNAME }}
          NIFI_PASSWORD=${{ secrets.NIFI_PASSWORD }}
          NIFI_SENSITIVE_PROPS_KEY=${{ secrets.NIFI_SENSITIVE_PROPS_KEY }}
          VM_PUBLIC_IP=$VM_IP
          NIFI_WEB_PROXY_HOST=$VM_IP:8443
          NIFI_HTTPS_PORT=${{ secrets.NIFI_HTTPS_PORT }}
          NIFI_REGISTRY_PORT=${{ secrets.NIFI_REGISTRY_PORT }}
          EOF
          chmod 600 ~/nificicd-g1p2/.env.$ENV"
          
          echo "Environment file updated"
          
          # Fix permissions
          ssh -i ~/.ssh/nifi_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            $VM_USER@$VM_IP "sudo chown -R $VM_USER:$VM_USER ~/nificicd-g1p2/config/ 2>/dev/null || true"
          
          # Validate Docker Compose
          echo "Validating Docker Compose..."
          ssh -i ~/.ssh/nifi_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            $VM_USER@$VM_IP "cd ~/nificicd-g1p2 && docker compose -f compose.$ENV.yml --env-file .env.$ENV config --quiet"
          
          [ $? -eq 0 ] && echo "Docker Compose valid" || exit 1
          
          # Verify setup
          echo "Verifying setup..."
          ssh -i ~/.ssh/nifi_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            $VM_USER@$VM_IP "bash -lc 'nifi_check_config'" || true

      - name: Display Success Message
        run: |
          ENV="${{ matrix.environment }}"
          
          cat <<SUCCESS
          
          ╔═══════════════════════════════╗
          ║  VM Provisioned & Configured  ║
          ╚═══════════════════════════════╝
          
          Environment: $ENV
          
          FULLY AUTOMATED SETUP COMPLETE!
          
          - GitHub PAT configured from GH_TOKEN
          - Git repository initialized
          - Post-commit hook installed
          - Helper scripts ready
          - Environment file created (.env.$ENV)
          - Permissions configured
          - Docker Compose validated
          
          ───────────────────────────────────────────
           You can now test immediately:
          ───────────────────────────────────────────
          
          SSH: ssh ${{ secrets.VM_USERNAME }}@<vm-ip>
          Verify: nifi_check_config
          Deploy: cd ~/nificicd-g1p2 && docker compose -f compose.$ENV.yml --env-file .env.$ENV up -d
          Test: nifi_trigger_workflow 'test'
          Monitor: https://github.com/${{ github.repository }}/actions
          
          SUCCESS

      - name: Wait Between Environments
        if: success()
        run: |
          ENVIRONMENTS='${{ needs.determine-environments.outputs.environments }}'
          CURRENT_ENV="${{ matrix.environment }}"
          LAST_ENV=$(echo "$ENVIRONMENTS" | jq -r '.[-1]')
          
          [ "$CURRENT_ENV" != "$LAST_ENV" ] && echo "Waiting ${{ github.event.inputs.wait_time }}s..." && sleep ${{ github.event.inputs.wait_time }}

  cleanup-on-failure:
    name: Cleanup Failed Infrastructure
    needs: [determine-environments, provision-and-configure]
    if: always() && needs.provision-and-configure.result == 'failure' && github.event.inputs.terraform_destroy_on_failure == 'true'
    runs-on: ubuntu-22.04
    strategy:
      matrix:
        environment: ${{ fromJson(needs.determine-environments.outputs.environments) }}
      fail-fast: false
    environment: ${{ matrix.environment }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: |
            {
              "clientId": "${{ secrets.ARM_CLIENT_ID }}",
              "clientSecret": "${{ secrets.ARM_CLIENT_SECRET }}",
              "subscriptionId": "${{ secrets.ARM_SUBSCRIPTION_ID }}",
              "tenantId": "${{ secrets.ARM_TENANT_ID }}"
            }

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~> 1.5"
          terraform_wrapper: false

      - name: Destroy Failed Infrastructure
        working-directory: ./azure-vm-terraform
        env:
          ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
          ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
          TF_VAR_environment: ${{ matrix.environment }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_azure_subscription_id: ${{ secrets.ARM_SUBSCRIPTION_ID }}
        run: |
          ENV="${{ matrix.environment }}"
          
          cat <<CLEANUP
          
          ╔═══════════════════════════════════════════╗
          ║ Auto-Cleanup: Destroying Failed Resources ║
          ╚═══════════════════════════════════════════╝
          Environment: $ENV
          
          CLEANUP
          
          terraform init -input=false
          
          if terraform destroy -var-file="${ENV}.tfvars" -auto-approve; then
            echo -e "\nInfrastructure cleaned up for $ENV"
          else
            echo -e "\nCleanup may be incomplete - verify manually"
            
            # Fallback to Azure CLI
            RG_SUFFIX="${ENV/development/dev}"
            RG="rg-nificicd-g1p2-$RG_SUFFIX"
            
            if az group exists --name $RG | grep -q "true"; then
              echo "Attempting Azure CLI cleanup..."
              az group delete --name $RG --yes --no-wait
              echo "Cleanup initiated via Azure CLI"
            fi
          fi

  summary:
    name: Provisioning Summary
    needs: [determine-environments, provision-and-configure, cleanup-on-failure]
    if: always()
    runs-on: ubuntu-22.04
    steps:
      - name: Display Summary
        run: |
          STATUS="${{ needs.provision-and-configure.result }}"
          CLEANUP="${{ needs.cleanup-on-failure.result }}"
          
          cat <<SUMMARY
          
          ╔════════════════════════════════════════╗
          ║  Infrastructure Provisioning Complete  ║
          ╚════════════════════════════════════════╝
          
          Environments: ${{ needs.determine-environments.outputs.environment_list }}
          Status: $STATUS
          $([ "$CLEANUP" = "success" ] && echo "Cleanup: Failed infrastructure cleaned up")
          
          SUMMARY
          
          if [ "$STATUS" = "success" ]; then
            cat <<SUCCESS
          All VMs provisioned and configured (FULLY AUTOMATED)
          
          What was configured automatically:
          
            - VMs provisioned on Azure
            - Docker installed and configured
            - GitHub PAT configured from GH_TOKEN
            - Git repositories initialized
            - Post-commit hooks installed
            - Helper scripts deployed
            - Environment files created (.env.{environment})
            - Permissions fixed (config directory)
            - Docker Compose configurations validated
          
          Ready to Use Immediately!
          
          Test on any VM:
            1. SSH: ssh azureuser@<vm-ip>
            2. Verify: nifi_check_config
            3. Deploy: cd ~/nificicd-g1p2 && docker compose -f compose.{env}.yml --env-file .env.{env} up -d
            4. Test: nifi_trigger_workflow 'test'
          
          Monitor: https://github.com/${{ github.repository }}/actions
          
          Documentation:
            - VMs: ~/SETUP_INSTRUCTIONS.md
            - GitHub: docs/Complete-CI-CD-Flow.md
          
          SUCCESS
          else
            cat <<FAILURE
          Some environments failed to provision
          
          FAILURE
            
            if [ "${{ github.event.inputs.terraform_destroy_on_failure }}" = "true" ]; then
              [ "$CLEANUP" = "success" ] && echo "Failed infrastructure auto-cleaned" || echo "Auto-cleanup may have failed - verify manually"
            else
              cat <<MANUAL
          Auto-cleanup was disabled
            - Force recreate: Run workflow with force_recreate=true
            - Manual: Delete resource groups from Azure Portal
          
          MANUAL
            fi
            
            echo "Check workflow logs for details"
          fi